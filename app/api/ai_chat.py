"""
AI Chat API â€” Unified AI-powered store building via chat.

Multi-provider AI chain:
  1. Anthropic Claude (primary)
  2. OpenAI GPT (fallback)
  3. Google Gemini (second fallback)
  4. Local modifications (offline fallback)

With Supabase integration for conversation storage.
"""

from typing import Annotated, Optional
import time
import logging

import httpx

from fastapi import APIRouter, Depends, Request, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession

from app.config import get_settings
from app.database import get_db
from app.middleware.auth import CurrentUser
from app.middleware.rate_limit import limiter
from app.schemas.ai_chat import (
    AIChatRequest,
    AIChatResponse,
    AIConversationRequest,
    AIConversationResponse,
)

router = APIRouter()
settings = get_settings()
logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Supabase Helper for Saving Conversations
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def _save_conversation_to_supabase(
    user_id: str,
    store_id: Optional[str],
    message: str,
    response: str,
    html_before: Optional[str] = None,
    html_after: Optional[str] = None,
    execution_time: Optional[float] = None,
):
    """Save AI conversation to Supabase for learning and analytics."""
    if not settings.SUPABASE_URL or not settings.SUPABASE_SERVICE_KEY:
        return  # Skip if Supabase not configured
    
    try:
        headers = {
            "apikey": settings.SUPABASE_SERVICE_KEY,
            "Authorization": f"Bearer {settings.SUPABASE_SERVICE_KEY}",
            "Content-Type": "application/json",
            "Prefer": "return=minimal",
        }
        
        data = {
            "user_id": user_id,
            "messages": [
                {"role": "user", "content": message},
                {"role": "assistant", "content": response},
            ],
        }
        
        if store_id:
            data["project_id"] = store_id
        
        async with httpx.AsyncClient(timeout=5.0) as client:
            await client.post(
                f"{settings.SUPABASE_URL}/rest/v1/chat_history",
                headers=headers,
                json=data,
            )
    except Exception as e:
        # Non-blocking - just log the error
        print(f"âš ï¸ Supabase save error (non-critical): {e}")


CONVERSATION_SYSTEM_PROMPT = """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…ØªØ§Ø¬Ø± Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. Ø§Ø³Ù…Ùƒ "Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…ØªØ¬Ø± Ø§Ù„Ø°ÙƒÙŠ".

## Ø´Ø®ØµÙŠØªÙƒ
- ÙˆØ¯ÙˆØ¯ØŒ Ù…Ø­ØªØ±ÙØŒ ÙˆÙ…ØªØ­Ù…Ø³ Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
- ØªØªØ­Ø¯Ø« Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ ÙˆÙ…ÙÙ‡ÙˆÙ…
- ØªØ³ØªØ®Ø¯Ù… Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ø¨Ø´ÙƒÙ„ Ù…Ø¹ØªØ¯Ù„ ğŸ˜Š
- Ø±Ø¯ÙˆØ¯Ùƒ Ù…Ø®ØªØµØ±Ø© ÙˆÙ…ÙÙŠØ¯Ø© (2-4 Ø¬Ù…Ù„ Ø¹Ø§Ø¯Ø©Ù‹)

## Ù…Ù‡Ù…ØªÙƒ
1. ØªØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙŠ ØªØ­Ø¯ÙŠØ¯ Ø±Ø¤ÙŠØªÙ‡ Ù„Ù…ØªØ¬Ø±Ù‡ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
2. ØªØ³Ø£Ù„Ù‡ Ø¹Ù† ØªÙØ¶ÙŠÙ„Ø§ØªÙ‡: Ø§Ù„Ø£Ù„ÙˆØ§Ù†ØŒ Ø§Ù„Ø³ØªØ§ÙŠÙ„ØŒ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù†ØªØ¬Ø§ØªØŒ Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©
3. ØªÙ‚ØªØ±Ø­ Ø£ÙÙƒØ§Ø± ÙˆØªØ­Ø³ÙŠÙ†Ø§Øª
4. ØªØ´Ø±Ø­ Ù…Ø§ ÙŠÙ…ÙƒÙ†Ùƒ ÙØ¹Ù„Ù‡

## Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ù‡Ù…Ø©
- Ù„Ø§ ØªÙˆÙ„Ù‘Ø¯ Ø£ÙŠ ÙƒÙˆØ¯ HTML Ø£Ùˆ CSS â€” ÙÙ‚Ø· Ù…Ø­Ø§Ø¯Ø«Ø© Ù†ØµÙŠØ©
- Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙƒÙˆÙ† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¬Ø§Ù‡Ø²Ø§Ù‹ Ù„Ù„ØªÙ†ÙÙŠØ°ØŒ Ø§Ù‚ØªØ±Ø­ Ø¹Ù„ÙŠÙ‡ ÙŠÙ‚ÙˆÙ„ "Ù†ÙÙ‘Ø°" Ø£Ùˆ "Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø¨Ù†Ø§Ø¡"
- Ù„Ø§ ØªÙƒØªØ¨ Ø±Ø¯ÙˆØ¯ Ø·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ø§Ù‹ â€” ÙƒÙ† Ù…Ø®ØªØµØ±Ø§Ù‹ ÙˆÙ…Ø±ÙƒØ²Ø§Ù‹
- Ø¥Ø°Ø§ Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„ ØªÙ‚Ù†ÙŠ Ø¹Ù† Ø§Ù„Ù…ØªØ¬Ø± Ø£Ø¬Ø¨ Ø¨Ø´ÙƒÙ„ ÙˆØ§Ø¶Ø­
- ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù‚ØªØ±Ø§Ø­ Ø£Ù‚Ø³Ø§Ù…: Ù‡ÙŠØ±ÙˆØŒ Ù…Ù†ØªØ¬Ø§ØªØŒ Ø¹Ø±ÙˆØ¶ØŒ ØªÙ‚ÙŠÙŠÙ…Ø§ØªØŒ ÙÙˆØªØ±ØŒ Ù‚Ø³Ù… Ø¹Ù†Ù‘Ø§ØŒ Ø£Ø³Ø¦Ù„Ø© Ø´Ø§Ø¦Ø¹Ø©

## Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ¬Ø±
- Ø§Ø³Ù… Ø§Ù„Ù…ØªØ¬Ø±: {store_name}
- Ù†ÙˆØ¹ Ø§Ù„Ù…ØªØ¬Ø±: {store_type}

## Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…ØªØ§Ø¬Ø±
- general: Ù…ØªØ¬Ø± Ø¹Ø§Ù…
- fashion: Ø£Ø²ÙŠØ§Ø¡ ÙˆÙ…ÙˆØ¶Ø©
- electronics: Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ§Øª
- food: Ù…Ø£ÙƒÙˆÙ„Ø§Øª ÙˆÙ…Ø·Ø§Ø¹Ù…
- beauty: ØªØ¬Ù…ÙŠÙ„ ÙˆØ¹Ù†Ø§ÙŠØ©
- home: Ø£Ø«Ø§Ø« ÙˆÙ…Ù†Ø²Ù„
- books: ÙƒØªØ¨ ÙˆÙ…ÙƒØªØ¨Ø§Øª
- sports: Ø±ÙŠØ§Ø¶Ø© ÙˆÙ„ÙŠØ§Ù‚Ø©"""


CHAT_SYSTEM_PROMPT = """Ø£Ù†Øª AI Store Builder Pro - Ø¹Ø¨Ù‚Ø±ÙŠ ØªØµÙ…ÙŠÙ… Ø§Ù„Ù…ØªØ§Ø¬Ø± Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©!

## Ù…Ù‡Ù…ØªÙƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
ØªØ­ÙˆÙŠÙ„ Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ù„Ù‰ ÙƒÙˆØ¯ HTML/CSS ÙƒØ§Ù…Ù„ ÙˆÙ…Ø°Ù‡Ù„ Ù„Ù…ØªØ§Ø¬Ø± Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ© Ø§Ø­ØªØ±Ø§ÙÙŠØ©.

## Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„ØµØ§Ø±Ù…Ø©
1. Ø£Ø±Ø¬Ø¹ HTML ÙƒØ§Ù…Ù„ ÙÙ‚Ø· â€” Ù…Ù† <!DOCTYPE html> Ø¥Ù„Ù‰ </html>
2. Ù„Ø§ ØªØ¶Ù Ø£ÙŠ Ø´Ø±Ø­ Ø£Ùˆ markdown â€” ÙÙ‚Ø· ÙƒÙˆØ¯ HTML
3. Ø¶Ø¹ ÙƒÙ„ CSS Ø¯Ø§Ø®Ù„ <style> ÙÙŠ <head> â€” Ù„Ø§ CSS Ø®Ø§Ø±Ø¬ÙŠ
4. Ø§Ø³ØªØ®Ø¯Ù… font-family: 'Tajawal', sans-serif Ù„Ù„Ø¹Ø±Ø¨ÙŠØ© 
5. Ø£Ø¶Ù link Ù„Ø®Ø· Tajawal Ù…Ù† Google Fonts ÙÙŠ <head>
6. ÙƒÙ„ Ø§Ù„ØªØµÙ…ÙŠÙ… ÙŠÙƒÙˆÙ† RTL (dir="rtl" lang="ar")
7. Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† responsive (mobile-first)

## Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØªØµÙ…ÙŠÙ…
- Ø§Ø³ØªØ®Ø¯Ù… CSS Variables Ù„Ù„Ø£Ù„ÙˆØ§Ù†: --primary, --secondary, --bg, --text
- Ø§Ø³ØªØ®Ø¯Ù… gradients Ø§Ø­ØªØ±Ø§ÙÙŠØ© ÙÙŠ Hero sections
- Ø£Ø¶Ù hover effects Ùˆtransitions Ø³Ù„Ø³Ø© (transition: all 0.3s ease)
- Ø§Ø³ØªØ®Ø¯Ù… box-shadow Ù„Ù„Ø¨Ø·Ø§Ù‚Ø§Øª ÙˆØ§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©
- ØªØ£ÙƒØ¯ Ù…Ù† contrast Ø¬ÙŠØ¯ Ù„Ù„Ù‚Ø±Ø§Ø¡Ø© (WCAG AA)
- Ø§Ø³ØªØ®Ø¯Ù… emoji ğŸ›ï¸ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¹ØµØ±ÙŠØ© Ù„Ù„Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª

## Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù…ØªØ§Ø­Ø©
- Hero Banner: Ø¹Ù†ÙˆØ§Ù† + ÙˆØµÙ + CTA + gradient
- Products Grid: Ø¨Ø·Ø§Ù‚Ø§Øª Ù…Ù†ØªØ¬Ø§Øª Ù…Ø¹ ØµÙˆØ± ÙˆØ£Ø³Ø¹Ø§Ø± Ùˆbadges
- Categories: Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù…ØªØ¬Ø± Ù…Ø¹ Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª
- Features: Ù…Ø²Ø§ÙŠØ§ Ø§Ù„Ù…ØªØ¬Ø± (ØªÙˆØµÙŠÙ„ØŒ Ø¯ÙØ¹ØŒ Ø¶Ù…Ø§Ù†)
- Offers/Sales: Ø¹Ø±ÙˆØ¶ ÙˆØªØ®ÙÙŠØ¶Ø§Øª Ù…Ø¹ countdown
- Newsletter: Ø§Ø´ØªØ±Ø§Ùƒ Ø¨Ø±ÙŠØ¯ÙŠ
- Footer: Ù…Ø¹Ù„ÙˆÙ…Ø§Øª + Ø±ÙˆØ§Ø¨Ø· + ØªÙˆØ§ØµÙ„ Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ
- Testimonials: ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡
- FAQ: Ø£Ø³Ø¦Ù„Ø© Ø´Ø§Ø¦Ø¹Ø©

## Ø¹Ù†Ø¯ ØªØ¹Ø¯ÙŠÙ„ ÙƒÙˆØ¯ Ù…ÙˆØ¬ÙˆØ¯
- Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù…Ø§ Ù„Ù… ÙŠØ·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØªØºÙŠÙŠØ±Ù‡Ø§ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
- Ø·Ø¨Ù‘Ù‚ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ÙÙ‚Ø· Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
- Ù„Ø§ ØªØ­Ø°Ù Ø£Ù‚Ø³Ø§Ù… Ù„Ù… ÙŠØ·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø­Ø°ÙÙ‡Ø§

## Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø©
- Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø¨Ø§Ù„Ø±ÙŠØ§Ù„ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ (Ø±.Ø³) Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹
- Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø£Ø²Ø±Ø§Ø± ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ø¹Ø¨Ø±Ø©
- Ø§Ø³ØªØ®Ø¯Ù… spacing Ù…ØªÙ†Ø§Ø³Ù‚ (8px grid)"""


async def _call_anthropic_chat(current_html: str, user_message: str, api_key: str) -> str:
    """Call Anthropic Claude to modify the store HTML."""
    import anthropic

    client = anthropic.AsyncAnthropic(api_key=api_key)
    message = await client.messages.create(
        model=settings.CLAUDE_MODEL,
        max_tokens=settings.AI_MAX_TOKENS,
        system=CHAT_SYSTEM_PROMPT,
        messages=[
            {
                "role": "user",
                "content": f"Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ø§Ù„ÙŠ:\n```html\n{current_html}\n```\n\nØ·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {user_message}\n\nØ£Ø±Ø¬Ø¹ HTML Ø§Ù„ÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø¹Ø¯Ù‘Ù„ ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø´Ø±Ø­ Ø£Ùˆ markdown):",
            },
        ],
    )
    content = message.content[0].text
    return _clean_ai_response(content)


async def _call_openai_chat(current_html: str, user_message: str, api_key: str) -> str:
    """Call OpenAI GPT to modify the store HTML (first fallback)."""
    from openai import AsyncOpenAI

    client = AsyncOpenAI(api_key=api_key, timeout=90.0)
    response = await client.chat.completions.create(
        model=settings.GPT_MODEL,
        messages=[
            {"role": "system", "content": CHAT_SYSTEM_PROMPT},
            {
                "role": "user",
                "content": f"Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ø§Ù„ÙŠ:\n```html\n{current_html}\n```\n\nØ·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {user_message}\n\nØ£Ø±Ø¬Ø¹ HTML Ø§Ù„ÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø¹Ø¯Ù‘Ù„ ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø´Ø±Ø­ Ø£Ùˆ markdown):",
            },
        ],
        temperature=settings.AI_TEMPERATURE,
        max_tokens=settings.AI_MAX_TOKENS,
    )
    content = response.choices[0].message.content or ""
    return _clean_ai_response(content)


async def _call_gemini_chat(current_html: str, user_message: str, api_key: str) -> str:
    """Call Google Gemini to modify the store HTML (second fallback)."""
    import google.generativeai as genai

    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(
        model_name=settings.GEMINI_MODEL,
        system_instruction=CHAT_SYSTEM_PROMPT,
    )

    prompt = f"Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ø§Ù„ÙŠ:\n```html\n{current_html}\n```\n\nØ·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {user_message}\n\nØ£Ø±Ø¬Ø¹ HTML Ø§Ù„ÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø¹Ø¯Ù‘Ù„ ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø´Ø±Ø­ Ø£Ùˆ markdown):"
    
    response = await model.generate_content_async(
        prompt,
        generation_config=genai.GenerationConfig(
            temperature=settings.AI_TEMPERATURE,
            max_output_tokens=settings.AI_MAX_TOKENS,
        ),
    )
    content = response.text or ""
    return _clean_ai_response(content)


def _clean_ai_response(content: str) -> str:
    """Remove markdown code fences from AI responses."""
    content = content.strip()
    if content.startswith("```"):
        lines = content.split("\n")
        # Remove first line (```html or ```)
        lines = lines[1:]
        # Remove last line if it's ```
        if lines and lines[-1].strip() == "```":
            lines = lines[:-1]
        content = "\n".join(lines)
    return content.strip()


def _apply_local_modifications(current_html: str, message: str) -> tuple[str, str]:
    """Apply basic color/text modifications locally when no API key is available."""
    html = current_html
    changes: list[str] = []

    color_map = {
        "Ø£Ø®Ø¶Ø±": ("#00b894", "#00a085"),
        "Ø£Ø­Ù…Ø±": ("#e74c3c", "#c0392b"),
        "Ø£Ø²Ø±Ù‚": ("#0984e3", "#0652DD"),
        "Ø°Ù‡Ø¨ÙŠ": ("#d4af37", "#b8960c"),
        "Ø¨Ø±ØªÙ‚Ø§Ù„ÙŠ": ("#e17055", "#d63031"),
        "ÙˆØ±Ø¯ÙŠ": ("#fd79a8", "#e84393"),
        "Ø¨Ù†ÙØ³Ø¬ÙŠ": ("#6c5ce7", "#4834d4"),
        "Ø£Ø³ÙˆØ¯": ("#2d3436", "#1e272e"),
        "ÙƒØ­Ù„ÙŠ": ("#2c3e50", "#1a252f"),
    }

    for color_name, (primary, dark) in color_map.items():
        if color_name in message:
            html = html.replace("#6c5ce7", primary).replace("#4834d4", dark)
            changes.append(f"ØªÙ… ØªØºÙŠÙŠØ± Ø§Ù„Ù„ÙˆÙ† Ø¥Ù„Ù‰ {color_name}")
            break

    if "ÙØ§Ø®Ø±" in message or "luxury" in message.lower():
        html = html.replace("background: #fafafa", "background: #0a0a1a")
        html = html.replace("color: #1a1a2e", "color: #f0e6d2")
        html = html.replace("background: white", "background: #1a1a2e")
        html = html.replace("background: #f8f8fc", "background: #0d0d20")
        html = html.replace("#6c5ce7", "#d4af37").replace("#4834d4", "#1a0a2e")
        changes.append("ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØµÙ…ÙŠÙ… Ù„Ø³ØªØ§ÙŠÙ„ ÙØ§Ø®Ø±")

    if "Ø¯Ø§ÙƒÙ†" in message or "dark" in message.lower():
        html = html.replace("background: #fafafa", "background: #0f0f23")
        html = html.replace("color: #1a1a2e", "color: #e0e0e0")
        html = html.replace("background: white", "background: #1a1a3e")
        html = html.replace("background: #f8f8fc", "background: #16163a")
        html = html.replace("color: #444", "color: #ccc")
        html = html.replace("color: #666", "color: #999")
        html = html.replace("border-bottom: 1px solid #eee", "border-bottom: 1px solid #333")
        changes.append("ØªÙ… ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¯Ø§ÙƒÙ†")

    if "6 Ù…Ù†ØªØ¬Ø§Øª" in message or "Ù…Ù†ØªØ¬Ø§Øª Ø£ÙƒØ«Ø±" in message or "Ø£Ø¶Ù Ù…Ù†ØªØ¬Ø§Øª" in message:
        extra_products = """
      <div class="product-card"><div class="product-img">ğŸ</div><div class="info"><div class="name">Ù…Ù†ØªØ¬ Ø­ØµØ±ÙŠ 5</div><div class="price">299 Ø±.Ø³</div></div></div>
      <div class="product-card"><div class="product-img">ğŸ›ï¸</div><div class="info"><div class="name">Ù…Ù†ØªØ¬ Ù…Ù…ÙŠØ² 6</div><div class="price">349 Ø±.Ø³</div></div></div>"""
        html = html.replace(
            '</div>\n  </div>\n  <div class="features">',
            f'{extra_products}\n    </div>\n  </div>\n  <div class="features">',
        )
        changes.append("ØªÙ… Ø¥Ø¶Ø§ÙØ© Ù…Ù†ØªØ¬Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©")

    if "Ø¹Ø±ÙˆØ¶" in message or "ØªØ®ÙÙŠØ¶Ø§Øª" in message:
        offers_section = """
  <div style="background: linear-gradient(135deg, #e74c3c, #c0392b); padding: 40px 24px; text-align: center; color: white;">
    <h2 style="font-size: 1.8rem; font-weight: 800; margin-bottom: 8px;">ğŸ”¥ Ø¹Ø±ÙˆØ¶ Ø­ØµØ±ÙŠØ©</h2>
    <p style="font-size: 1.1rem; opacity: 0.9; margin-bottom: 16px;">Ø®ØµÙˆÙ…Ø§Øª ØªØµÙ„ Ø¥Ù„Ù‰ 50% Ø¹Ù„Ù‰ Ù…Ù†ØªØ¬Ø§Øª Ù…Ø®ØªØ§Ø±Ø©</p>
    <button style="background: white; color: #e74c3c; border: none; padding: 12px 28px; border-radius: 10px; font-weight: 700; font-size: 1rem; cursor: pointer; font-family: 'Tajawal', sans-serif;">ØªØ³ÙˆÙ‚ Ø§Ù„Ø¹Ø±ÙˆØ¶</button>
  </div>"""
        html = html.replace(
            '<div class="features">', f'{offers_section}\n  <div class="features">'
        )
        changes.append("ØªÙ… Ø¥Ø¶Ø§ÙØ© Ù‚Ø³Ù… Ø§Ù„Ø¹Ø±ÙˆØ¶")

    if "Ø¨Ø§Ù†Ø±" in message:
        html = html.replace(
            "padding: 80px 24px",
            "padding: 100px 24px; background-size: cover; background-position: center",
        )
        html = html.replace(
            "font-size: 2.5rem", "font-size: 3rem; text-shadow: 2px 2px 8px rgba(0,0,0,0.3)"
        )
        changes.append("ØªÙ… ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¨Ø§Ù†Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ")

    if not changes:
        changes.append("ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª")

    return html, " â€” ".join(changes)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Conversation AI (chat without HTML generation)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def _call_anthropic_conversation(
    messages: list[dict],
    system_prompt: str,
    api_key: str,
) -> str:
    """Call Anthropic Claude for conversation (no HTML)."""
    import anthropic

    client = anthropic.AsyncAnthropic(api_key=api_key)
    response = await client.messages.create(
        model=settings.CLAUDE_MODEL,
        max_tokens=1024,
        system=system_prompt,
        messages=messages,
    )
    return response.content[0].text


async def _call_openai_conversation(
    messages: list[dict],
    system_prompt: str,
    api_key: str,
) -> str:
    """Call OpenAI for conversation (no HTML)."""
    from openai import AsyncOpenAI

    client = AsyncOpenAI(api_key=api_key, timeout=30.0)
    all_messages = [{"role": "system", "content": system_prompt}] + messages
    response = await client.chat.completions.create(
        model=settings.GPT_MODEL,
        messages=all_messages,
        temperature=0.8,
        max_tokens=1024,
    )
    return response.choices[0].message.content or ""


async def _call_gemini_conversation(
    messages: list[dict],
    system_prompt: str,
    api_key: str,
) -> str:
    """Call Gemini for conversation (no HTML)."""
    import google.generativeai as genai

    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(
        model_name=settings.GEMINI_MODEL,
        system_instruction=system_prompt,
    )

    # Convert messages to Gemini format
    history_text = "\n".join(
        f"{'Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…' if m['role'] == 'user' else 'Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯'}: {m['content']}"
        for m in messages[:-1]
    )
    last_msg = messages[-1]["content"] if messages else ""
    prompt = f"{history_text}\nØ§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {last_msg}" if history_text else last_msg

    response = await model.generate_content_async(
        prompt,
        generation_config=genai.GenerationConfig(temperature=0.8, max_output_tokens=1024),
    )
    return response.text or ""


def _get_conversation_suggestions(message: str, store_type: str) -> list[str]:
    """Return conversation suggestions based on context."""
    suggestions_map = {
        "fashion": [
            "Ø£Ø¨ÙŠ Ø£Ù„ÙˆØ§Ù† Ø£Ù†Ø«ÙˆÙŠØ© Ù…Ø«Ù„ Ø§Ù„ÙˆØ±Ø¯ÙŠ ÙˆØ§Ù„Ø°Ù‡Ø¨ÙŠ",
            "Ø£Ø¶Ù Ù‚Ø³Ù… Ø£Ø­Ø¯Ø« Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª",
            "Ø£Ø¨ÙŠ Ù‚Ø³Ù… Ø¹Ø±ÙˆØ¶ Ù…Ø¹ Ø®ØµÙˆÙ…Ø§Øª",
            "Ù†ÙÙ‘Ø° Ø§Ù„ØªØµÙ…ÙŠÙ…",
        ],
        "electronics": [
            "Ø£Ø¨ÙŠ ØªØµÙ…ÙŠÙ… ØªÙ‚Ù†ÙŠ Ø­Ø¯ÙŠØ« Ø¨Ø£Ù„ÙˆØ§Ù† Ø²Ø±Ù‚Ø§Ø¡",
            "Ø£Ø¶Ù Ù‚Ø³Ù… Ø£ÙƒØ«Ø± Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ù…Ø¨ÙŠØ¹Ø§Ù‹",
            "Ø£Ø¨ÙŠ Ù‚Ø³Ù… Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª",
            "Ù†ÙÙ‘Ø° Ø§Ù„ØªØµÙ…ÙŠÙ…",
        ],
        "food": [
            "Ø£Ø¨ÙŠ Ø£Ù„ÙˆØ§Ù† Ø¯Ø§ÙØ¦Ø© ØªØ´Ù‡Ù‘ÙŠ",
            "Ø£Ø¶Ù Ù‚Ø³Ù… Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø·Ø¹Ø§Ù…",
            "Ø£Ø¨ÙŠ Ù‚Ø³Ù… ØªÙˆØµÙŠÙ„ Ù…Ø¹ Ø§Ù„Ø£ÙˆÙ‚Ø§Øª",
            "Ù†ÙÙ‘Ø° Ø§Ù„ØªØµÙ…ÙŠÙ…",
        ],
        "general": [
            "ÙˆØ´ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù„ÙŠ ØªØ¨ÙŠ ØªØ¨ÙŠØ¹Ù‡Ø§ØŸ",
            "Ø£Ø¨ÙŠ ØªØµÙ…ÙŠÙ… ÙØ§Ø®Ø± ÙˆØ£Ù†ÙŠÙ‚",
            "Ø£Ø¶Ù Ù‚Ø³Ù… Ø¹Ø±ÙˆØ¶ ÙˆØªØ®ÙÙŠØ¶Ø§Øª",
            "Ù†ÙÙ‘Ø° Ø§Ù„ØªØµÙ…ÙŠÙ…",
        ],
    }
    base = suggestions_map.get(store_type, suggestions_map["general"])
    msg_lower = message.lower()
    return [s for s in base if not any(word in msg_lower for word in s.split()[:2])][:4]


@router.post("/conversation", response_model=AIConversationResponse)
@limiter.limit("20/minute")
async def ai_conversation(
    request: Request,
    body: AIConversationRequest,
    current_user: CurrentUser,
    db: Annotated[AsyncSession, Depends(get_db)],
):
    """Conversational AI endpoint â€” chat about the store without generating HTML."""
    start_time = time.time()

    system_prompt = CONVERSATION_SYSTEM_PROMPT.format(
        store_name=body.store_name,
        store_type=body.store_type,
    )

    # Build messages list (keep last 20 messages for context)
    messages = []
    for msg in body.conversation_history[-20:]:
        role = msg.get("role", "user")
        if role == "ai":
            role = "assistant"
        if role in ("user", "assistant"):
            messages.append({"role": role, "content": msg.get("content", "")})
    messages.append({"role": "user", "content": body.message})

    reply = ""
    anthropic_key = settings.ANTHROPIC_API_KEY
    openai_key = settings.OPENAI_API_KEY
    google_key = settings.GOOGLE_API_KEY

    # Try providers in order
    if anthropic_key:
        try:
            reply = await _call_anthropic_conversation(messages, system_prompt, anthropic_key)
        except Exception as e:
            logger.warning(f"Anthropic conversation error: {e}")

    if not reply and openai_key:
        try:
            reply = await _call_openai_conversation(messages, system_prompt, openai_key)
        except Exception as e:
            logger.warning(f"OpenAI conversation error: {e}")

    if not reply and google_key:
        try:
            reply = await _call_gemini_conversation(messages, system_prompt, google_key)
        except Exception as e:
            logger.warning(f"Gemini conversation error: {e}")

    if not reply:
        reply = (
            f"Ù…Ø±Ø­Ø¨Ø§Ù‹! ğŸ‘‹ Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ù„Ø¨Ù†Ø§Ø¡ Ù…ØªØ¬Ø± \"{body.store_name}\".\n\n"
            "Ø£Ø®Ø¨Ø±Ù†ÙŠ Ø¹Ù† Ø±Ø¤ÙŠØªÙƒ Ù„Ù„Ù…ØªØ¬Ø± â€” Ø§Ù„Ø£Ù„ÙˆØ§Ù†ØŒ Ø§Ù„Ø³ØªØ§ÙŠÙ„ØŒ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª â€” "
            "ÙˆØ¨Ø¹Ø¯ÙŠÙ† Ù‚ÙˆÙ„ \"Ù†ÙÙ‘Ø°\" ÙˆØ£Ù†Ø§ Ø£Ø¨Ù†ÙŠÙ‡ Ù„Ùƒ! ğŸš€"
        )

    execution_time = round(time.time() - start_time, 2)

    # Save to Supabase
    try:
        await _save_conversation_to_supabase(
            user_id=str(current_user.id),
            store_id=None,
            message=body.message,
            response=reply,
            execution_time=execution_time,
        )
    except Exception:
        pass

    return AIConversationResponse(
        reply=reply,
        suggestions=_get_conversation_suggestions(body.message, body.store_type),
        should_execute=False,
        execution_time=execution_time,
    )


@router.post("/chat", response_model=AIChatResponse)
@limiter.limit("10/minute")
async def ai_chat(
    request: Request,
    body: AIChatRequest,
    current_user: CurrentUser,
    db: Annotated[AsyncSession, Depends(get_db)],
):
    """Process an AI chat message and return updated store HTML."""
    start_time = time.time()
    
    anthropic_key = settings.ANTHROPIC_API_KEY
    openai_key = settings.OPENAI_API_KEY
    google_key = settings.GOOGLE_API_KEY
    new_html = ""
    response_message = ""
    provider_used = "local"

    # Priority 1: Anthropic Claude (primary)
    if anthropic_key and not new_html:
        try:
            new_html = await _call_anthropic_chat(
                body.current_html, body.message, anthropic_key,
            )
            response_message = f"âœ… Claude: ØªÙ… ØªØ·Ø¨ÙŠÙ‚ '{body.message}' Ø¨Ø°ÙƒØ§Ø¡"
            provider_used = "anthropic"
        except Exception as e:
            logger.warning(f"Anthropic error: {e}")

    # Priority 2: OpenAI GPT (first fallback)
    if not new_html and openai_key:
        try:
            new_html = await _call_openai_chat(
                body.current_html, body.message, openai_key,
            )
            response_message = f"âœ… GPT: ØªÙ… ØªØ·Ø¨ÙŠÙ‚ '{body.message}'"
            provider_used = "openai"
        except Exception as e:
            logger.warning(f"OpenAI error: {e}")

    # Priority 3: Google Gemini (second fallback)
    if not new_html and google_key:
        try:
            new_html = await _call_gemini_chat(
                body.current_html, body.message, google_key,
            )
            response_message = f"âœ… Gemini: ØªÙ… ØªØ·Ø¨ÙŠÙ‚ '{body.message}'"
            provider_used = "google"
        except Exception as e:
            logger.warning(f"Gemini error: {e}")

    # Priority 4: Local modifications (offline fallback)
    if not new_html:
        new_html, description = _apply_local_modifications(
            body.current_html, body.message,
        )
        response_message = f"{description} âœ…"
        provider_used = "local"
    
    execution_time = round(time.time() - start_time, 2)
    
    # Save conversation to Supabase (async, non-blocking)
    try:
        await _save_conversation_to_supabase(
            user_id=str(current_user.id),
            store_id=body.store_id,
            message=body.message,
            response=response_message,
            html_before=body.current_html[:500] if body.current_html else None,
            html_after=new_html[:500] if new_html else None,
            execution_time=execution_time,
        )
    except Exception as e:
        logger.debug(f"Supabase save skipped: {e}")
    
    return AIChatResponse(
        html=new_html,
        message=response_message,
        suggestions=_get_suggestions(body.message),
        execution_time=execution_time,
    )


def _get_suggestions(last_message: str) -> list[str]:
    """Return context-aware suggestions based on the last message."""
    suggestions = [
        "ØºÙŠÙ‘Ø± Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ù„Ø£Ø®Ø¶Ø±",
        "Ø£Ø¶Ù Ù‚Ø³Ù… Ø¹Ø±ÙˆØ¶",
        "Ø®Ù„Ù‘Ù‡ ÙˆØ¶Ø¹ Ø¯Ø§ÙƒÙ†",
        "Ø£Ø¶Ù Ù…Ù†ØªØ¬Ø§Øª Ø£ÙƒØ«Ø±",
        "Ø­Ø³Ù‘Ù† Ø§Ù„Ø¨Ø§Ù†Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ",
    ]
    # Filter out suggestions similar to what was just asked
    msg_lower = last_message.lower()
    return [s for s in suggestions if not any(word in msg_lower for word in s.split()[:2])][:3]


# â•â•â•â•â•â•â• Ø§Ø®ØªØ¨Ø§Ø± AI Ø¨Ø¯ÙˆÙ† Ù…ØµØ§Ø¯Ù‚Ø© (Ù„Ù„ØªØ·ÙˆÙŠØ±) â•â•â•â•â•â•â•
@router.post("/test", response_model=AIChatResponse)
async def ai_chat_test_endpoint(
    request: Request,
    req: AIChatRequest,
) -> AIChatResponse:
    """Ø§Ø®ØªØ¨Ø§Ø± AI Chat Ø¨Ø¯ÙˆÙ† Ù…ØµØ§Ø¯Ù‚Ø© â€” Ù…ÙÙŠØ¯ Ù„Ù„ØªØ·ÙˆÙŠØ± ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø±."""
    start_time = time.time()
    
    api_key = settings.ANTHROPIC_API_KEY
    
    if not api_key:
        # Try OpenAI
        if settings.OPENAI_API_KEY:
            try:
                html = await _call_openai_chat(req.current_html, req.message, settings.OPENAI_API_KEY)
                return AIChatResponse(
                    html=html,
                    message="âœ… GPT: ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…ØªØ¬Ø±",
                    execution_time=round(time.time() - start_time, 2),
                )
            except Exception:
                pass
        
        # Try Gemini
        if settings.GOOGLE_API_KEY:
            try:
                html = await _call_gemini_chat(req.current_html, req.message, settings.GOOGLE_API_KEY)
                return AIChatResponse(
                    html=html,
                    message="âœ… Gemini: ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…ØªØ¬Ø±",
                    execution_time=round(time.time() - start_time, 2),
                )
            except Exception:
                pass
        
        # Local fallback
        modified_html, message = _apply_local_modifications(req.current_html, req.message)
        return AIChatResponse(
            html=modified_html,
            message=f"âœ… ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ù…Ø­Ù„ÙŠØ©: {message}",
            execution_time=round(time.time() - start_time, 2),
        )
    
    try:
        enhanced_html = await _call_anthropic_chat(
            current_html=req.current_html,
            user_message=req.message,
            api_key=api_key,
        )
        
        return AIChatResponse(
            html=enhanced_html,
            message="ğŸ¨ Claude Ø¹Ø¯Ù‘Ù„ Ù…ØªØ¬Ø±Ùƒ Ø¨Ø°ÙƒØ§Ø¡! Ø´ÙˆÙ Ø§Ù„Ù†ØªÙŠØ¬Ø© ğŸ‘ˆ",
            execution_time=round(time.time() - start_time, 2),
        )
    except Exception as e:
        logger.error(f"Claude API error in test: {type(e).__name__}: {e}")
        modified_html, message = _apply_local_modifications(req.current_html, req.message)
        return AIChatResponse(
            html=modified_html,
            message=f"âš ï¸ Ù†Ø¸Ø§Ù… Ù…Ø­Ù„ÙŠ: {message}",
            execution_time=round(time.time() - start_time, 2),
        )
